{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_data.gz', compression='gzip')\n",
    "df = df.drop(['Unnamed: 0'], axis=1).set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_history_encoded_single_exp(orig_df, history_length):\n",
    "    hist_df = orig_df.copy(deep=True) # later operations are \"in place\" so we need to avoid changing original dataframe\n",
    "    columns_to_shift = hist_df.columns[:-1] # omit the action column, we don't want to duplicate it\n",
    "    for i in range(1,history_length + 1):\n",
    "        shift_df = orig_df.shift(i)\n",
    "        for col_name in columns_to_shift:\n",
    "            new_col_name = \"prev_{0}_\".format(i) + col_name\n",
    "            hist_df[new_col_name] = shift_df[col_name] # add shifted column, aka history, as a column to orignal dataframe\n",
    "            \n",
    "    hist_df = hist_df[history_length:] # we don't return the first \"history_length\" sample - they have missing history data\n",
    "    return hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_history_encoded_df(orig_df, history_length, expirements, participants):\n",
    "    dfs_to_concate = []\n",
    "    cols_to_drop = ['partc', 'action_file_index']\n",
    "    for e in expirements:\n",
    "        for p in participants:\n",
    "            exp_df = orig_df[(orig_df['partc'] == p) & (orig_df['action_file_index'] == e)]\n",
    "            exp_df = exp_df.drop(cols_to_drop, axis=1)\n",
    "            exp_histoy_df = create_history_encoded_single_exp(exp_df, history_length)\n",
    "#             print \"finished history encoding for expirement {0} and participant {1}\".format(e, p)\n",
    "            dfs_to_concate.append(exp_histoy_df)\n",
    "    return pd.concat(dfs_to_concate, axis=0, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exps = range(1,9+1) + range(11,16+1) # no expirement 10\n",
    "parts = range(1,24+1) # 24 participants\n",
    "\n",
    "# use history_length=10 just to be consistent with sliding window, can try encoding more/less history\n",
    "hist_df = create_history_encoded_df(df, history_length=5, expirements=exps, participants=parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 15 expirements and 24 participants in each expirement <br>\n",
    "for history encoded data with history length of 10 samples we are loosing 10 data samples of each expirement <br>\n",
    "that sums up to 15 \\* 24 \\* 10 = 3600 <br>\n",
    "and indeed in the new data set there are exactly 3600 rows fewer than the origial data set <br>\n",
    "and on the other hand exacly 12 * {history_length + 1 (for original data)} + label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1411065, 73)\n",
      "(1412865, 15)\n",
      "wlk    343928\n",
      "sit    338538\n",
      "std    306187\n",
      "ups    156925\n",
      "jog    133991\n",
      "dws    131496\n",
      "Name: action, dtype: int64\n",
      "wlk    344288\n",
      "sit    338778\n",
      "std    306427\n",
      "ups    157285\n",
      "jog    134231\n",
      "dws    131856\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print hist_df.shape\n",
    "print df.shape\n",
    "print hist_df[\"action\"].value_counts()\n",
    "print df[\"action\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffle the data and divide to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hist_df = hist_df.sample(frac=1).reset_index(drop=True) # shuffle the dataset\n",
    "# X, y = hist_df.drop([\"action\"], axis=1), hist_df[\"action\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# num_training = int(hist_df.shape[0] * 0.8)\n",
    "# # use 80% for training and 20% for test. if parameters tunning is needed use cross-validation not the test data!\n",
    "# X_train, y_train = X[:num_training], y[:num_training]\n",
    "# X_test, y_test = X[num_training:], y[num_training:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the history data frame as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist_df.to_pickle(\"history_5_encoded.pkl\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
