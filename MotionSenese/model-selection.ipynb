{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join(os.getcwd(), 'motionsense-dataset')\n",
    "subjects_info_path = os.path.join(root_path, 'data_subjects_info.csv')\n",
    "data_root_path = os.path.join(root_path, 'A_DeviceMotion_data')\n",
    "num_participants = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_dir(num_participants, root_path, dir_path):\n",
    "    '''\n",
    "    Receives a single experiment dirname\n",
    "    and returns a list of dataframes for each subject\n",
    "    of the specified experiment\n",
    "    '''\n",
    "    dfs = []\n",
    "    for i in range(1, num_participants + 1):\n",
    "        file_name = 'sub_' + str(i) + '.csv'\n",
    "        file_path = os.path.join(root_path, dir_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframes_from_files(num_participants, root_path, data_dirs):\n",
    "    '''\n",
    "    Receives a list of directories\n",
    "    and returns a list of dataframes for each subject\n",
    "    and each experiment specified\n",
    "    '''\n",
    "    dfs = []\n",
    "    for dir_path in data_dirs:\n",
    "        dir_dfs = dataframe_from_dir(num_participants, root_path, dir_path)\n",
    "        dfs.extend(dir_dfs)\n",
    "    return dfs       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframes_to_feature_vectors(dfs, feature, num_cols):\n",
    "    '''\n",
    "    Receives a list of dataframes and a feature\n",
    "    and returns a dataframe and a matrix\n",
    "    where each column is a timestamp.\n",
    "    Note that the number of columns (i.e.) timestamps\n",
    "    is constant, and should refer to the minimal experiment.\n",
    "    '''\n",
    "    data_matrix = []\n",
    "    \n",
    "    for df in dfs:\n",
    "        values = df[feature].head(num_cols).tolist()\n",
    "        data_matrix.append(values)\n",
    "    \n",
    "    feature_df = pd.DataFrame(data_matrix)\n",
    "    return feature_df, data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sit vs. Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = ['sit_5', 'sit_13', 'wlk_7', 'wlk_8']\n",
    "test_dirs = ['wlk_15']\n",
    "train_labels = 48 * [0]\n",
    "train_labels.extend(48 * [1])\n",
    "test_labels = 24 * [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = dataframes_from_files(num_participants, data_root_path, train_dirs)\n",
    "test_dfs = dataframes_from_files(num_participants, data_root_path, test_dirs)\n",
    "dfs = train_dfs + test_dfs\n",
    "num_cols = min(df.shape[0] for df in dfs) # Cut to minimum experiment length\n",
    "features = dfs[0].columns.tolist()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SVM(train_set, train_labels, test_set, test_labels):\n",
    "    '''\n",
    "    Returns the 0-1 loss and the predicted labels\n",
    "    '''\n",
    "    \n",
    "    classifier = svm.SVC()\n",
    "    classifier.fit(train_set, train_labels)\n",
    "    \n",
    "    predicted_labels = []\n",
    "    for sample in test_set:\n",
    "        predicted_labels.append(classifier.predict([sample])[0])\n",
    "    \n",
    "    loss = sum(abs(prediction - label) for prediction, label in zip(predicted_labels, test_labels))\n",
    "    loss /= len(test_labels)\n",
    "    \n",
    "    return predicted_labels, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SVM for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "\n",
    "for feature in features:\n",
    "    train_feature_df, train_set = dataframes_to_feature_vectors(train_dfs, feature, num_cols)\n",
    "    test_feature_df, test_set = dataframes_to_feature_vectors(test_dfs, feature, num_cols)\n",
    "    \n",
    "    predictions, loss = run_SVM(train_set, train_labels, test_set, test_labels)\n",
    "    scores[feature] = 1 - loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attitude.pitch': 0.9583333333333334,\n",
       " 'attitude.roll': 0.7916666666666666,\n",
       " 'attitude.yaw': 0.625,\n",
       " 'gravity.x': 0.8333333333333334,\n",
       " 'gravity.y': 0.9583333333333334,\n",
       " 'gravity.z': 1.0,\n",
       " 'rotationRate.x': 1.0,\n",
       " 'rotationRate.y': 1.0,\n",
       " 'rotationRate.z': 0.875,\n",
       " 'userAcceleration.x': 0.20833333333333337,\n",
       " 'userAcceleration.y': 0.9583333333333334,\n",
       " 'userAcceleration.z': 0.625}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly not a clean result since we only test on 24 same-label samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_label(dir_name, experiment_labels):\n",
    "    return experiment_labels[dir_name[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dirs = [dir for dir in os.walk(data_root_path)][0][1]\n",
    "experiment_labels = {\n",
    "    'sit': 0,\n",
    "    'dws': 1,\n",
    "    'jog': 2,\n",
    "    'std': 3,\n",
    "    'ups': 4,\n",
    "    'wlk': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10292,\n",
       " 9220,\n",
       " 12303,\n",
       " 9099,\n",
       " 9609,\n",
       " 7760,\n",
       " 11383,\n",
       " 9657,\n",
       " 11125,\n",
       " 9397,\n",
       " 7926,\n",
       " 8050,\n",
       " 9901,\n",
       " 12757,\n",
       " 9820,\n",
       " 11001,\n",
       " 11221,\n",
       " 8923,\n",
       " 11690,\n",
       " 7937,\n",
       " 10326,\n",
       " 8466,\n",
       " 6106,\n",
       " 10688,\n",
       " 10292,\n",
       " 3712,\n",
       " 1894,\n",
       " 3069,\n",
       " 4296,\n",
       " 4090,\n",
       " 4918,\n",
       " 4720,\n",
       " 5081,\n",
       " 5864,\n",
       " 7650,\n",
       " 2934,\n",
       " 3274,\n",
       " 2928,\n",
       " 5979,\n",
       " 4225,\n",
       " 3106,\n",
       " 4494,\n",
       " 4962,\n",
       " 2522,\n",
       " 4137,\n",
       " 3557,\n",
       " 3031,\n",
       " 3386,\n",
       " 5439,\n",
       " 7681,\n",
       " 6410,\n",
       " 6471,\n",
       " 4735,\n",
       " 7088,\n",
       " 6864,\n",
       " 6122,\n",
       " 7104,\n",
       " 6402,\n",
       " 6626,\n",
       " 6742,\n",
       " 5464,\n",
       " 6767,\n",
       " 6934,\n",
       " 7366,\n",
       " 6996,\n",
       " 8402,\n",
       " 6678,\n",
       " 7026,\n",
       " 7360,\n",
       " 6442,\n",
       " 6505,\n",
       " 5021,\n",
       " 4340,\n",
       " 5614,\n",
       " 5194,\n",
       " 5336,\n",
       " 3841,\n",
       " 5176,\n",
       " 4883,\n",
       " 4828,\n",
       " 4754,\n",
       " 6111,\n",
       " 4889,\n",
       " 4860,\n",
       " 3782,\n",
       " 4695,\n",
       " 4906,\n",
       " 5446,\n",
       " 4665,\n",
       " 5973,\n",
       " 5295,\n",
       " 5014,\n",
       " 6304,\n",
       " 4948,\n",
       " 5441,\n",
       " 4076,\n",
       " 1333,\n",
       " 6305,\n",
       " 3594,\n",
       " 3768,\n",
       " 2436,\n",
       " 2459,\n",
       " 2957,\n",
       " 2620,\n",
       " 2334,\n",
       " 2257,\n",
       " 1630,\n",
       " 2614,\n",
       " 1775,\n",
       " 2241,\n",
       " 2582,\n",
       " 2744,\n",
       " 2216,\n",
       " 2388,\n",
       " 3227,\n",
       " 2861,\n",
       " 3192,\n",
       " 2373,\n",
       " 3306,\n",
       " 2060]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.shape[0] for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"sit_15\"[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.extend([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 3, 4]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
