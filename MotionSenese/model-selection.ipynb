{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.join(os.getcwd(), 'motionsense-dataset')\n",
    "subjects_info_path = os.path.join(root_path, 'data_subjects_info.csv')\n",
    "data_root_path = os.path.join(root_path, 'A_DeviceMotion_data')\n",
    "num_participants = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_from_dir(num_participants, root_path, dir_path):\n",
    "    '''\n",
    "    Receives a single experiment dirname\n",
    "    and returns a list of dataframes for each subject\n",
    "    of the specified experiment\n",
    "    '''\n",
    "    dfs = []\n",
    "    for i in range(1, num_participants + 1):\n",
    "        file_name = 'sub_' + str(i) + '.csv'\n",
    "        file_path = os.path.join(root_path, dir_path, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframes_from_files(num_participants, root_path, data_dirs):\n",
    "    '''\n",
    "    Receives a list of directories\n",
    "    and returns a list of dataframes for each subject\n",
    "    and each experiment specified\n",
    "    '''\n",
    "    dfs = []\n",
    "    for dir_path in data_dirs:\n",
    "        dir_dfs = dataframe_from_dir(num_participants, root_path, dir_path)\n",
    "        dfs.extend(dir_dfs)\n",
    "    return dfs       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframes_to_feature_vectors(dfs, feature, num_cols):\n",
    "    '''\n",
    "    Receives a list of dataframes and a feature\n",
    "    and returns a dataframe and a matrix\n",
    "    where each column is a timestamp.\n",
    "    Note that the number of columns (i.e.) timestamps\n",
    "    is constant, and should refer to the minimal experiment.\n",
    "    '''\n",
    "    data_matrix = []\n",
    "    \n",
    "    for df in dfs:\n",
    "        values = df[feature].head(num_cols).tolist()\n",
    "        data_matrix.append(values)\n",
    "    \n",
    "    feature_df = pd.DataFrame(data_matrix)\n",
    "    return feature_df, data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sit vs. Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = ['sit_5', 'sit_13', 'wlk_7', 'wlk_8']\n",
    "test_dirs = ['wlk_15']\n",
    "train_labels = 48 * [0]\n",
    "train_labels.extend(48 * [1])\n",
    "test_labels = 24 * [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = dataframes_from_files(num_participants, data_root_path, train_dirs)\n",
    "test_dfs = dataframes_from_files(num_participants, data_root_path, test_dirs)\n",
    "dfs = train_dfs + test_dfs\n",
    "num_cols = min(df.shape[0] for df in dfs) # Cut to minimum experiment length\n",
    "features = dfs[0].columns.tolist()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SVM(train_set, train_labels, test_set, test_labels):\n",
    "    '''\n",
    "    Returns the 0-1 loss and the predicted labels\n",
    "    '''\n",
    "    \n",
    "    classifier = svm.SVC()\n",
    "    classifier.fit(train_set, train_labels)\n",
    "    \n",
    "    predicted_labels = []\n",
    "    for sample in test_set:\n",
    "        predicted_labels.append(classifier.predict([sample])[0])\n",
    "    \n",
    "    loss = sum(abs(prediction - label) for prediction, label in zip(predicted_labels, test_labels))\n",
    "    loss /= len(test_labels)\n",
    "    \n",
    "    return predicted_labels, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SVM for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "\n",
    "for feature in features:\n",
    "    train_feature_df, train_set = dataframes_to_feature_vectors(train_dfs, feature, num_cols)\n",
    "    test_feature_df, test_set = dataframes_to_feature_vectors(test_dfs, feature, num_cols)\n",
    "    \n",
    "    predictions, loss = run_SVM(train_set, train_labels, test_set, test_labels)\n",
    "    scores[feature] = 1 - loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attitude.pitch': 0.9583333333333334,\n",
       " 'attitude.roll': 0.7916666666666666,\n",
       " 'attitude.yaw': 0.625,\n",
       " 'gravity.x': 0.8333333333333334,\n",
       " 'gravity.y': 0.9583333333333334,\n",
       " 'gravity.z': 1.0,\n",
       " 'rotationRate.x': 1.0,\n",
       " 'rotationRate.y': 1.0,\n",
       " 'rotationRate.z': 0.875,\n",
       " 'userAcceleration.x': 0.20833333333333337,\n",
       " 'userAcceleration.y': 0.9583333333333334,\n",
       " 'userAcceleration.z': 0.625}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly not a clean result since we only test on 24 same-label samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_label(dir_name, experiment_labels):\n",
    "    return experiment_labels[dir_name[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dirs = [dir for dir in os.walk(data_root_path)][0][1]\n",
    "experiment_labels = {\n",
    "    'sit': 0,\n",
    "    'dws': 1,\n",
    "    'jog': 2,\n",
    "    'std': 3,\n",
    "    'ups': 4,\n",
    "    'wlk': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
