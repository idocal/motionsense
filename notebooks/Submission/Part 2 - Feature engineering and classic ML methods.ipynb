{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MotiononSense Dataset : Smartphone Sensor Data </h1>\n",
    "<h3> Problem definition - predicts user's activity base on phone sensors data </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Part 2:\n",
    "<ul>\n",
    "    <li> Problem definition and possible applications </li>\n",
    "    <li> Feature extraction/engineering </li>\n",
    "    <li> Classic ML models - training and statistical evaluation </li>\n",
    "    <li> Problems and the need for \"real data\" </li>\n",
    "    </ul>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Problem definition and applications </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li> Our probelm is predicting user's activity from phone sensors data </li>\n",
    "    <li> This definition might be too wide, so we limit ourself to predicting 1 of 5 possible activities </li>\n",
    "    <li> Thus, we can define our problem as multiclass classification, where we can label each data point as <br>\n",
    "        sitting, standing, walking, going downstaris or going upstairs </li>\n",
    "    <li> There are many application for this kind of classification in various fields such as <br>\n",
    "        healthcare, intelligence etc. </li>\n",
    "    <li> We will further discuss some of these applications in later part of our project </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Feature extraction/engineering </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is a time series - a sequence of measurments over time\n",
    "<ul>\n",
    "    <li> Thus, extracting value for a single data point depends on it's context </li> \n",
    "    <li> But, classic ML algorithms/classifiers predicts output for a single input data point - independent to ajdecent input data point </li>\n",
    "    <li> So, in order to use our data to train classic ML model we will have to encode our features to represent context data </li>\n",
    "    <li> We will present two different features encoding methods - Sliding-Window and Raw-History </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Sliding Window Features </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li> In this method, we will encode each data sample as a concatenation of anayltical functions calculated over a predefined size of previous samples </li>\n",
    "<li> For example, here we will use a context size of 10 (calculate over 10 pervious data points) </li>\n",
    "<li> Notice that we cannot mix between different expirements who represents different activity label </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "PROJECT_MAIN_DIR = os.path.join(os.getcwd(), \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindow:\n",
    "    \n",
    "    def __init__(self, orig_df, window_size, num_experiments, num_participants, exclude, fnlist):\n",
    "        exps = [i for i in range(1,num_experiments + 1) if i != exclude]\n",
    "        parts = [i for i in range(1,num_participants + 1)]\n",
    "        smp_df = self.create_sliding_df(orig_df, window_size, fnlist, exps, parts)\n",
    "        self.window_size = window_size\n",
    "        self.df = smp_df\n",
    "\n",
    "    def create_sld_df_single_exp(self, orig_df, window_size, analytic_functions_list):\n",
    "        dfs_to_concate = []\n",
    "        base_df = orig_df.drop('action', axis=1)\n",
    "        for func in analytic_functions_list:\n",
    "            method_to_call = getattr(base_df.rolling(window=window_size), func)\n",
    "            analytic_df = method_to_call()\n",
    "            analytic_df = analytic_df[window_size:]\n",
    "            analytic_df.columns = [col + \"_sld_\" + func for col in analytic_df.columns]\n",
    "            dfs_to_concate.append(analytic_df)\n",
    "\n",
    "        action_df = orig_df[['action']][window_size:] # [[]] syntax to return DataFrame and not Series\n",
    "        dfs_to_concate.append(action_df)\n",
    "        return pd.concat(dfs_to_concate,axis=1)\n",
    "\n",
    "    def create_sliding_df(self, orig_df, window_size, analytic_functions_list, expirements, participants):\n",
    "        dfs_to_concate = []\n",
    "        cols_to_drop = ['partc', 'action_file_index']\n",
    "        for e in expirements:\n",
    "            for p in participants:\n",
    "                exp_df = orig_df[(orig_df['partc'] == p) & (orig_df['action_file_index'] == e)]\n",
    "                exp_df = exp_df.drop(cols_to_drop, axis=1)\n",
    "                exp_roll_df = self.create_sld_df_single_exp(exp_df, window_size, analytic_functions_list)\n",
    "\n",
    "                dfs_to_concate.append(exp_roll_df)\n",
    "        return pd.concat(dfs_to_concate, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(PROJECT_MAIN_DIR,'full_data.gz'), compression='gzip') # we will load our data saved as a compressed csv file\n",
    "df = df.drop(['Unnamed: 0'], axis=1).set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables for the sliding window data frame creation\n",
    "num_experiments = 16\n",
    "num_participants = 24\n",
    "exclude = 10\n",
    "analytic_functions_list = ['mean', 'sum', 'median', 'min', 'max', 'std']\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "# create the sliding window data frame\n",
    "win_df = SlidingWindow(df, WINDOW_SIZE, num_experiments, num_participants, exclude, analytic_functions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing our data and performing sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude.roll_sld_mean</th>\n",
       "      <th>attitude.pitch_sld_mean</th>\n",
       "      <th>attitude.yaw_sld_mean</th>\n",
       "      <th>gravity.x_sld_mean</th>\n",
       "      <th>gravity.y_sld_mean</th>\n",
       "      <th>gravity.z_sld_mean</th>\n",
       "      <th>rotationRate.x_sld_mean</th>\n",
       "      <th>rotationRate.y_sld_mean</th>\n",
       "      <th>rotationRate.z_sld_mean</th>\n",
       "      <th>userAcceleration.x_sld_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>gravity.x_sld_std</th>\n",
       "      <th>gravity.y_sld_std</th>\n",
       "      <th>gravity.z_sld_std</th>\n",
       "      <th>rotationRate.x_sld_std</th>\n",
       "      <th>rotationRate.y_sld_std</th>\n",
       "      <th>rotationRate.z_sld_std</th>\n",
       "      <th>userAcceleration.x_sld_std</th>\n",
       "      <th>userAcceleration.y_sld_std</th>\n",
       "      <th>userAcceleration.z_sld_std</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.476032</td>\n",
       "      <td>-0.699698</td>\n",
       "      <td>0.659227</td>\n",
       "      <td>0.761074</td>\n",
       "      <td>0.643965</td>\n",
       "      <td>-0.072516</td>\n",
       "      <td>0.327435</td>\n",
       "      <td>-0.237590</td>\n",
       "      <td>0.125294</td>\n",
       "      <td>0.089179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.029224</td>\n",
       "      <td>0.346436</td>\n",
       "      <td>0.590791</td>\n",
       "      <td>0.249107</td>\n",
       "      <td>0.083854</td>\n",
       "      <td>0.128267</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>dws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.464487</td>\n",
       "      <td>-0.697192</td>\n",
       "      <td>0.650675</td>\n",
       "      <td>0.761804</td>\n",
       "      <td>0.642056</td>\n",
       "      <td>-0.081426</td>\n",
       "      <td>0.344311</td>\n",
       "      <td>-0.346253</td>\n",
       "      <td>0.059212</td>\n",
       "      <td>0.058162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.377046</td>\n",
       "      <td>0.554298</td>\n",
       "      <td>0.172086</td>\n",
       "      <td>0.087612</td>\n",
       "      <td>0.140744</td>\n",
       "      <td>0.099833</td>\n",
       "      <td>dws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.448353</td>\n",
       "      <td>-0.695176</td>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.761559</td>\n",
       "      <td>0.640510</td>\n",
       "      <td>-0.093848</td>\n",
       "      <td>0.481461</td>\n",
       "      <td>-0.525592</td>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.054865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.032387</td>\n",
       "      <td>0.428049</td>\n",
       "      <td>0.712118</td>\n",
       "      <td>0.141470</td>\n",
       "      <td>0.090179</td>\n",
       "      <td>0.146393</td>\n",
       "      <td>0.097535</td>\n",
       "      <td>dws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.426500</td>\n",
       "      <td>-0.692378</td>\n",
       "      <td>0.625654</td>\n",
       "      <td>0.760575</td>\n",
       "      <td>0.638354</td>\n",
       "      <td>-0.110722</td>\n",
       "      <td>0.602284</td>\n",
       "      <td>-0.699763</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>0.055195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.043814</td>\n",
       "      <td>0.439572</td>\n",
       "      <td>1.006450</td>\n",
       "      <td>0.168158</td>\n",
       "      <td>0.089927</td>\n",
       "      <td>0.148507</td>\n",
       "      <td>0.104310</td>\n",
       "      <td>dws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.399383</td>\n",
       "      <td>-0.688014</td>\n",
       "      <td>0.609652</td>\n",
       "      <td>0.758815</td>\n",
       "      <td>0.634966</td>\n",
       "      <td>-0.131806</td>\n",
       "      <td>0.705380</td>\n",
       "      <td>-0.951931</td>\n",
       "      <td>0.111215</td>\n",
       "      <td>0.041147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>0.062607</td>\n",
       "      <td>0.433246</td>\n",
       "      <td>1.329760</td>\n",
       "      <td>0.224856</td>\n",
       "      <td>0.074548</td>\n",
       "      <td>0.091135</td>\n",
       "      <td>0.131904</td>\n",
       "      <td>dws</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude.roll_sld_mean  attitude.pitch_sld_mean  attitude.yaw_sld_mean  \\\n",
       "0                1.476032                -0.699698               0.659227   \n",
       "1                1.464487                -0.697192               0.650675   \n",
       "2                1.448353                -0.695176               0.639860   \n",
       "3                1.426500                -0.692378               0.625654   \n",
       "4                1.399383                -0.688014               0.609652   \n",
       "\n",
       "   gravity.x_sld_mean  gravity.y_sld_mean  gravity.z_sld_mean  \\\n",
       "0            0.761074            0.643965           -0.072516   \n",
       "1            0.761804            0.642056           -0.081426   \n",
       "2            0.761559            0.640510           -0.093848   \n",
       "3            0.760575            0.638354           -0.110722   \n",
       "4            0.758815            0.634966           -0.131806   \n",
       "\n",
       "   rotationRate.x_sld_mean  rotationRate.y_sld_mean  rotationRate.z_sld_mean  \\\n",
       "0                 0.327435                -0.237590                 0.125294   \n",
       "1                 0.344311                -0.346253                 0.059212   \n",
       "2                 0.481461                -0.525592                 0.033799   \n",
       "3                 0.602284                -0.699763                 0.062317   \n",
       "4                 0.705380                -0.951931                 0.111215   \n",
       "\n",
       "   userAcceleration.x_sld_mean   ...    gravity.x_sld_std  gravity.y_sld_std  \\\n",
       "0                     0.089179   ...             0.003243           0.006475   \n",
       "1                     0.058162   ...             0.001706           0.004752   \n",
       "2                     0.054865   ...             0.002168           0.004552   \n",
       "3                     0.055195   ...             0.004032           0.005687   \n",
       "4                     0.041147   ...             0.007015           0.008968   \n",
       "\n",
       "   gravity.z_sld_std  rotationRate.x_sld_std  rotationRate.y_sld_std  \\\n",
       "0           0.029224                0.346436                0.590791   \n",
       "1           0.029167                0.377046                0.554298   \n",
       "2           0.032387                0.428049                0.712118   \n",
       "3           0.043814                0.439572                1.006450   \n",
       "4           0.062607                0.433246                1.329760   \n",
       "\n",
       "   rotationRate.z_sld_std  userAcceleration.x_sld_std  \\\n",
       "0                0.249107                    0.083854   \n",
       "1                0.172086                    0.087612   \n",
       "2                0.141470                    0.090179   \n",
       "3                0.168158                    0.089927   \n",
       "4                0.224856                    0.074548   \n",
       "\n",
       "   userAcceleration.y_sld_std  userAcceleration.z_sld_std  action  \n",
       "0                    0.128267                    0.114783     dws  \n",
       "1                    0.140744                    0.099833     dws  \n",
       "2                    0.146393                    0.097535     dws  \n",
       "3                    0.148507                    0.104310     dws  \n",
       "4                    0.091135                    0.131904     dws  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_df.df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Sanity check: </b> <br>\n",
    "<ul>\n",
    "    <li> There are 15 expirements and 24 participants for each expirement </li>\n",
    "    <li> For sliding window of 10 samples we are loosing 10 data samples of each expirement </li>\n",
    "    <li> This sums up to 15 \\* 24 \\* 10 = 3600 </li>\n",
    "    <li> Indeed in the new data set there are exactly 3600 rows fewer than the origial data set <\\li>\n",
    "    <li> Furthermore, the new data set has exactly 12 * {num_analytical_function} + label column = 12 \\* 6 + 1 = 73 columns <br>\n",
    "        (12 is the number of features in the original data set) </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409265, 73)\n",
      "(1412865, 15)\n"
     ]
    }
   ],
   "source": [
    "print(win_df.df.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Raw History Features </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>In this method, we will simply encode each data sample as a concatenation of the raw features of it's previous x data points </li>\n",
    "        <li>For example, here we will use a context size of 10. i.e it is aligned with our previous sliding window method, <br>\n",
    "but instead of calculating aggregation of analytical function over the context features, here we simply encode them as a long vector </li>\n",
    "    <li> Again, we cannot mix between different expirements who represents different activity label </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawHistory:\n",
    "    \n",
    "    def __init__(self, origin_df, history_length, num_experiments, num_participants, exclude):\n",
    "        exps = [i for i in range(1,num_experiments + 1) if i != exclude]\n",
    "        parts = [i for i in range(1,num_participants + 1)]\n",
    "        smp_df = self.create_history_encoded_df(df, history_length, expirements=exps, participants=parts)\n",
    "        self.history_length = history_length\n",
    "        self.df = smp_df\n",
    "\n",
    "    def create_history_encoded_single_exp(self, orig_df, history_length):\n",
    "        hist_df = orig_df.copy(deep=True) # later operations are \"in place\" so we need to avoid changing original dataframe\n",
    "        columns_to_shift = hist_df.columns[:-1] # omit the action column, we don't want to duplicate it\n",
    "        for i in range(1,history_length + 1):\n",
    "            shift_df = orig_df.shift(i)\n",
    "            for col_name in columns_to_shift:\n",
    "                new_col_name = \"prev_{0}_\".format(i) + col_name\n",
    "                hist_df[new_col_name] = shift_df[col_name] # add shifted column, aka history, as a column to orignal dataframe\n",
    "\n",
    "        hist_df = hist_df[history_length:] # we don't return the first \"history_length\" sample - they have missing history data\n",
    "        return hist_df\n",
    "\n",
    "    def create_history_encoded_df(self, orig_df, history_length, expirements, participants):\n",
    "        dfs_to_concate = []\n",
    "        cols_to_drop = ['partc', 'action_file_index']\n",
    "        for e in expirements:\n",
    "            for p in participants:\n",
    "                exp_df = orig_df[(orig_df['partc'] == p) & (orig_df['action_file_index'] == e)]\n",
    "                exp_df = exp_df.drop(cols_to_drop, axis=1)\n",
    "                exp_histoy_df = self.create_history_encoded_single_exp(exp_df, history_length)\n",
    "                dfs_to_concate.append(exp_histoy_df)\n",
    "        return pd.concat(dfs_to_concate, axis=0, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables for the raw history data frame creation\n",
    "num_experiments = 16\n",
    "num_participants = 24\n",
    "exclude = 10\n",
    "HISTORY_LEN = 10\n",
    "\n",
    "# create the sliding window data frame\n",
    "hist_df = RawHistory(df, HISTORY_LEN, num_experiments, num_participants, exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Sanity check: </b> <br>\n",
    "<ul>\n",
    "    <li> There are 15 expirements and 24 participants for each expirement </li>\n",
    "    <li> For history encoded data with history length of 10 samples we are loosing 10 data samples of each expirement\n",
    "this sums up to 15 \\* 24 \\* 10 = 3600 </li>\n",
    "    <li> This sums up to 15 \\* 24 \\* 10 = 3600 </li>\n",
    "    <li> Indeed in the new data set there are exactly 3600 rows fewer than the origial data set <\\li>\n",
    "    <li> Furthermore, the new data set has exactly 12 * {history_length + 1} + label columns = 12 * (10+1) + 1 = 133 columns <br>\n",
    "        (addition of one for the original data) </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409265, 133)\n",
      "(1412865, 15)\n"
     ]
    }
   ],
   "source": [
    "print(hist_df.df.shape)\n",
    "print(df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
