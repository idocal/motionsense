{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MotiononSense Dataset\n",
    "### Problem definition: predict user's activity based on smartphone sensors data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3:\n",
    "\n",
    "* Extracting Real World Data \n",
    "* Evaluation on Real World Data \n",
    "* Neural Models - Training and Evaluation on Real World Data\n",
    "* Applicative Predictions Smoothing\n",
    "* Final Results, Conculsions & Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extracting Real World Data\n",
    "\n",
    "\n",
    "* We used the [Core Motion Framework for iOS devices](https://developer.apple.com/documentation/coremotion/cmdevicemotion) to extract sensors data from our phones\n",
    "* More details on the app we built can be found in our final document\n",
    "* We recorded sensors data while performing different activties and extracted labeled data samples \n",
    "* On the next section we will load our data and use it as a test set to evaluate the performace of our Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class NewDataLoader():\n",
    "    \n",
    "    def __init__(self, folder_path):\n",
    "        self.data_path = folder_path\n",
    "    \n",
    "    def load_all_expirements(self):\n",
    "        df = None\n",
    "        exp_index = 1\n",
    "        for filename in os.listdir(self.data_path):\n",
    "            file_path = os.path.join(self.data_path, filename)\n",
    "            extension = os.path.splitext(file_path)[1]\n",
    "            if extension == '.csv':\n",
    "                current_df = self.load_single_test_expirement(file_path, exp_index)\n",
    "                exp_index += 1\n",
    "                if df is None:\n",
    "                    df = current_df\n",
    "                else:\n",
    "                    df = df.append(current_df)\n",
    "        return df\n",
    "\n",
    "    def load_single_test_expirement(self, path_to_file, exp_index, partc_id=1):\n",
    "        cols_to_drop = [\"timestamp\", \"timeIntervalSince1970\", 'magneticField.x', \n",
    "                        'magneticField.y', 'magneticField.z', 'magneticField.accuracy']\n",
    "        file_name = path_to_file.split(os.sep)[-1]\n",
    "        name, file_type = file_name.split('.')\n",
    "        action = name[:3]\n",
    "        exp_df = pd.read_csv(path_to_file)\n",
    "        exp_df = exp_df.drop(cols_to_drop, axis=1)\n",
    "        exp_df[\"partc\"] = partc_id\n",
    "        exp_df[\"action\"] = action\n",
    "        exp_df[\"action_file_index\"] = exp_index\n",
    "        return exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_MAIN_DIR = os.getcwd()\n",
    "path = os.path.join(PROJECT_MAIN_DIR, 'real-data')\n",
    "data_loader = NewDataLoader(path)\n",
    "real_test_df = data_loader.load_all_expirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load also our original data set and use it as a training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PROJECT_MAIN_DIR,'full_data.gz'), compression='gzip') # we will load our data saved as a compressed csv file\n",
    "train_df = train_df.drop(['Unnamed: 0'], axis=1).set_index('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation on Real World Data\n",
    "\n",
    "Now, we will encode both samples with our Sliding Window encoding, train our Random Forest model over the entire old data and evaluate it's performance on the real world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindow:\n",
    "    \n",
    "    def __init__(self, orig_df, window_size, num_experiments, num_participants, exclude, fnlist):\n",
    "        exps = [i for i in range(1,num_experiments + 1) if i != exclude]\n",
    "        parts = [i for i in range(1,num_participants + 1)]\n",
    "        smp_df = self.create_sliding_df(orig_df, window_size, fnlist, exps, parts)\n",
    "        self.window_size = window_size\n",
    "        self.df = smp_df\n",
    "\n",
    "    def create_sld_df_single_exp(self, orig_df, window_size, analytic_functions_list):\n",
    "        dfs_to_concate = []\n",
    "        base_df = orig_df.drop('action', axis=1)\n",
    "        for func in analytic_functions_list:\n",
    "            method_to_call = getattr(base_df.rolling(window=window_size), func)\n",
    "            analytic_df = method_to_call()\n",
    "            analytic_df = analytic_df[window_size:]\n",
    "            analytic_df.columns = [col + \"_sld_\" + func for col in analytic_df.columns]\n",
    "            dfs_to_concate.append(analytic_df)\n",
    "\n",
    "        action_df = orig_df[['action']][window_size:] # [[]] syntax to return DataFrame and not Series\n",
    "        dfs_to_concate.append(action_df)\n",
    "        return pd.concat(dfs_to_concate,axis=1)\n",
    "\n",
    "    def create_sliding_df(self, orig_df, window_size, analytic_functions_list, expirements, participants):\n",
    "        dfs_to_concate = []\n",
    "        cols_to_drop = ['partc', 'action_file_index']\n",
    "        for e in expirements:\n",
    "            for p in participants:\n",
    "                exp_df = orig_df[(orig_df['partc'] == p) & (orig_df['action_file_index'] == e)]\n",
    "                exp_df = exp_df.drop(cols_to_drop, axis=1)\n",
    "                exp_roll_df = self.create_sld_df_single_exp(exp_df, window_size, analytic_functions_list)\n",
    "\n",
    "                dfs_to_concate.append(exp_roll_df)\n",
    "        return pd.concat(dfs_to_concate, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables for the sliding window data frame creation\n",
    "num_experiments = 16\n",
    "num_participants = 24\n",
    "exclude = 10\n",
    "analytic_functions_list = ['mean', 'sum', 'median', 'min', 'max', 'std']\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "# create the sliding window data frame\n",
    "train_win_df = SlidingWindow(train_df, WINDOW_SIZE, num_experiments, num_participants, exclude, analytic_functions_list)\n",
    "train_win_df = train_win_df.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 18\n",
    "num_participants = 1\n",
    "exclude = 0\n",
    "analytic_functions_list = ['mean', 'sum', 'median', 'min', 'max', 'std']\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "real_test_df[\"partc\"] = 1\n",
    "test_win_df = SlidingWindow(real_test_df, WINDOW_SIZE, num_experiments, num_participants, exclude, analytic_functions_list)\n",
    "test_win_df = test_win_df.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class DataProcessingEval():\n",
    "    \n",
    "    def __init__(self, origin_df, labels_dict):\n",
    "        self.labels_dict = labels_dict\n",
    "        self.classes_names = self.create_classes(labels_dict)\n",
    "        self.df = origin_df\n",
    "    \n",
    "    def create_samples(self, division_ratio=[0.7, 0.1, 0.2]):\n",
    "        # Define X, y\n",
    "        df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        X, y = df.drop([\"action\"], axis=1), df[\"action\"]\n",
    "        y = y.replace(self.labels_dict)\n",
    "\n",
    "        # Divide to training, validation and test set\n",
    "        train_ratio, dev_ratio = division_ratio[0], division_ratio[1]\n",
    "        num_training = int(df.shape[0] * train_ratio)\n",
    "        num_validation = int(df.shape[0] * dev_ratio)\n",
    "        \n",
    "        X_train, y_train = X[:num_training], y[:num_training]\n",
    "        X_vald, y_vald = X[num_training:num_training + num_validation], y[num_training:num_training + num_validation]\n",
    "        X_test, y_test = X[num_training + num_validation:], y[num_training + num_validation:]\n",
    "\n",
    "        return X_train, y_train, X_vald, y_vald, X_test, y_test\n",
    "\n",
    "    def create_classes(self, labels_dict):\n",
    "        classes_indexs = labels_dict.items()\n",
    "        classes_indexs = sorted(classes_indexs, key=lambda x: x[1])\n",
    "        classes_names = [label for label, index in classes_indexs]\n",
    "        return classes_names\n",
    "\n",
    "    def evaluate_results(self, y_true, y_pred):\n",
    "            print(\"---- Printing classification report ----\")\n",
    "            print(classification_report(y_true, y_pred, target_names=self.classes_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'wlk': 0, 'sit': 1, \"std\": 2, \"ups\": 3, \"jog\": 4, \"dws\": 5}\n",
    "\n",
    "win_train_processor = DataProcessingEval(train_win_df, labels_dict=labels)\n",
    "X_train, y_train, _, _, _, _  = win_train_processor.create_samples([1.0, 0, 0])\n",
    "\n",
    "win_test_processor = DataProcessingEval(test_win_df, labels_dict=labels)\n",
    "X_test_real, y_test_real, _, _, _, _ = win_test_processor.create_samples([1.0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training over the entire original data and evaluating on new test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   48.1s remaining:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.65      0.48      0.55     52652\n",
      "        sit       0.98      0.69      0.81     35225\n",
      "        std       0.96      0.96      0.96     36561\n",
      "        ups       0.40      0.74      0.52     21800\n",
      "        jog       0.00      0.00      0.00         0\n",
      "        dws       0.40      0.45      0.42     19547\n",
      "\n",
      "avg / total       0.72      0.66      0.68    165785\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "/Users/okleinfeld/venv/ds_workshop/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=10, n_jobs=-1, verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_test_predictions = rf.predict(X_test_real)\n",
    "win_test_processor.evaluate_results(y_test_real, rf_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions so far:**\n",
    "\n",
    "* We excluded the \"jogging\" activity because we didn't perform this activity in the data we created from our app\n",
    "* As predicted, the results on real world data are much worse compared to results over our original test set\n",
    "* We are still predicting \"sit\" and \"stand\" activities quite well but our current model is having hard time identifying \"upstairs\" and \"down stairs\"\n",
    "* Next, we will try to use a stronger, neural models, hoping that it will help us increasing our performance over the real test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Neural Models - Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding for Neural Models**\n",
    "\n",
    "* The first model we will try is a simple feed forward network with one hidden layer\n",
    "* Feed forward nets, like classic ML models, cannot use sequence as input so we will have to use one of our previous encodings \n",
    "* We will choose our sliding window encoding first, since it out-performed our raw history encoding\n",
    "* We hope that our model can create a better representation of the data in it's hidden layer and thus increase the generalization ability of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1409265, 73)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_win_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "ff_model = Sequential()\n",
    "ff_model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))  # hidden layer size is 32\n",
    "ff_model.add(Dropout(dropout_rate))  # adding dropout layer\n",
    "ff_model.add(Dense(6, activation='softmax'))  # applying softmax and cross entorpy loss\n",
    "ff_model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1409265/1409265 [==============================] - 43s 31us/step - loss: 0.5436\n",
      "Epoch 2/5\n",
      "1409265/1409265 [==============================] - 44s 31us/step - loss: 0.4918\n",
      "Epoch 3/5\n",
      "1409265/1409265 [==============================] - 42s 30us/step - loss: 0.4860\n",
      "Epoch 4/5\n",
      "1409265/1409265 [==============================] - 45s 32us/step - loss: 0.4816\n",
      "Epoch 5/5\n",
      "1409265/1409265 [==============================] - 44s 32us/step - loss: 0.4799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e5bcda0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "num_activities = 6\n",
    "y_train_one_hot = np.array([to_categorical(t, num_activities) for t in y_train])\n",
    "\n",
    "# tranform y to one hot encoding vector of length 6 (we have 6 activities)\n",
    "ff_model.fit(X_train, y_train_one_hot, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.80      0.52      0.63     52652\n",
      "        sit       0.88      0.97      0.92     35225\n",
      "        std       0.89      0.97      0.93     36561\n",
      "        ups       0.32      0.66      0.43     21800\n",
      "        jog       0.00      0.00      0.00         0\n",
      "        dws       0.39      0.16      0.23     19547\n",
      "\n",
      "avg / total       0.73      0.69      0.68    165785\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/okleinfeld/venv/ds_workshop/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_test_real_one_hot = np.array([to_categorical(t, num_activities) for t in y_test_real])\n",
    "ff_predictions = ff_model.predict(X_test_real)\n",
    "ff_test_predictions = np.array([np.argmax(prediction) for prediction in ff_predictions])\n",
    "win_test_processor.evaluate_results(y_test_real, ff_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate results:**\n",
    "* Results for Feed Forward neural network look like the Random Forest ones\n",
    "* Try to add another hidden layer and see if significant improvement occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1409265/1409265 [==============================] - 50s 35us/step - loss: 0.4480\n",
      "Epoch 2/5\n",
      "1409265/1409265 [==============================] - 49s 35us/step - loss: 0.3645\n",
      "Epoch 3/5\n",
      "1409265/1409265 [==============================] - 47s 33us/step - loss: 0.3465\n",
      "Epoch 4/5\n",
      "1409265/1409265 [==============================] - 46s 33us/step - loss: 0.3352\n",
      "Epoch 5/5\n",
      "1409265/1409265 [==============================] - 47s 34us/step - loss: 0.3287\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.84      0.46      0.59     52652\n",
      "        sit       0.94      0.97      0.96     35225\n",
      "        std       0.95      0.97      0.96     36561\n",
      "        ups       0.42      0.74      0.54     21800\n",
      "        jog       0.00      0.00      0.00         0\n",
      "        dws       0.35      0.44      0.39     19547\n",
      "\n",
      "avg / total       0.77      0.71      0.72    165785\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/okleinfeld/venv/ds_workshop/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "ff2_model = Sequential()\n",
    "ff2_model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))  # first hidden layer size is 32\n",
    "ff2_model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))  # second hidden layer size is 32\n",
    "ff2_model.add(Dropout(dropout_rate))  # adding dropout layer\n",
    "ff2_model.add(Dense(6, activation='softmax'))  # applying softmax and cross entorpy loss\n",
    "ff2_model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "ff2_model.fit(X_train, y_train_one_hot, batch_size=32, epochs=5)\n",
    "\n",
    "ff2_predictions = ff2_model.predict(X_test_real)\n",
    "ff2_test_predictions = np.array([np.argmax(prediction) for prediction in ff2_predictions])\n",
    "win_test_processor.evaluate_results(y_test_real, ff2_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intermediate neural conclusions:**\n",
    "* Normal feed forward does not perform much better than random forest\n",
    "* Adding another layer did not improve at all the F1-score\n",
    "* This might be because our sliding window is not an ideal input for time series neural network\n",
    "* Try a recurrent neural network such as LSTM instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Recurrent Neural Network\n",
    "* We would need to use raw data, and not summarized like Sliding Window\n",
    "* Results may differ between vector sizes of **raw history** encoding\n",
    "* Ideally we would predict each experiment separately but our data only contains dozens of experiments\n",
    "* This means that another discreteziation method is required\n",
    "* We will again use a **predefined vector size** (i.e. 10) in our raw history encoding\n",
    "* Thus, We do not expect significant improvement comparing to the Feed Forward models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawHistory:\n",
    "    \n",
    "    def __init__(self, origin_df, history_length, num_experiments, num_participants, exclude):\n",
    "        exps = [i for i in range(1,num_experiments + 1) if i != exclude]\n",
    "        parts = [i for i in range(1,num_participants + 1)]\n",
    "        smp_df = self.create_history_encoded_df(origin_df, history_length, expirements=exps, participants=parts)\n",
    "        self.history_length = history_length\n",
    "        self.df = smp_df\n",
    "\n",
    "    def create_history_encoded_single_exp(self, orig_df, history_length):\n",
    "        hist_df = orig_df.copy(deep=True) # later operations are \"in place\" so we need to avoid changing original dataframe\n",
    "        columns_to_shift = hist_df.columns[:-1] # omit the action column, we don't want to duplicate it\n",
    "        for i in range(1,history_length + 1):\n",
    "            shift_df = orig_df.shift(i)\n",
    "            for col_name in columns_to_shift:\n",
    "                new_col_name = \"prev_{0}_\".format(i) + col_name\n",
    "                hist_df[new_col_name] = shift_df[col_name] # add shifted column, aka history, as a column to orignal dataframe\n",
    "\n",
    "        hist_df = hist_df[history_length:] # we don't return the first \"history_length\" sample - they have missing history data\n",
    "        return hist_df\n",
    "\n",
    "    def create_history_encoded_df(self, orig_df, history_length, expirements, participants):\n",
    "        dfs_to_concate = []\n",
    "        cols_to_drop = ['partc', 'action_file_index']\n",
    "        for e in expirements:\n",
    "            for p in participants:\n",
    "                exp_df = orig_df[(orig_df['partc'] == p) & (orig_df['action_file_index'] == e)]\n",
    "                exp_df = exp_df.drop(cols_to_drop, axis=1)\n",
    "                exp_histoy_df = self.create_history_encoded_single_exp(exp_df, history_length)\n",
    "                dfs_to_concate.append(exp_histoy_df)\n",
    "        return pd.concat(dfs_to_concate, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables for the raw history data frame creation\n",
    "num_experiments = 16\n",
    "num_participants = 24\n",
    "exclude = 10\n",
    "HISTORY_LEN = 10\n",
    "\n",
    "# create the raw history data frame for training\n",
    "train_hist_df = RawHistory(train_df, HISTORY_LEN, num_experiments, num_participants, exclude)\n",
    "train_hist_df = train_hist_df.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the raw history data frame for testing\n",
    "num_experiments = 18\n",
    "num_participants = 1\n",
    "exclude = 0\n",
    "HISTORY_LEN = 10\n",
    "\n",
    "test_hist_df = RawHistory(real_test_df, HISTORY_LEN, num_experiments, num_participants, exclude)\n",
    "test_hist_df = test_hist_df.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'wlk': 0, 'sit': 1, \"std\": 2, \"ups\": 3, \"jog\": 4, \"dws\": 5}\n",
    "\n",
    "hist_train_processor = DataProcessingEval(train_hist_df, labels_dict=labels)\n",
    "X_train, y_train, _, _, _, _  = hist_train_processor.create_samples([1.0, 0, 0])\n",
    "\n",
    "hist_test_processor = DataProcessingEval(test_hist_df, labels_dict=labels)\n",
    "X_test_real, y_test_real, _, _, _, _ = hist_test_processor.create_samples([1.0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The LSTM can deal with sequence of inputs, thus we don't need to explicitly encode our raw history as one long vectort as before.\n",
    "* We will pass to the LSTM model a sequence of 11 data points (10 history and actual data point)\n",
    "* Each data point is a vector of length 12 (our 12 origianl features)\n",
    "* Thus, we need to transform our raw encoding long vector to a sequence of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 12\n",
    "X_train = np.array(X_train)\n",
    "X_train = np.flip(X_train, axis=1)  # reverse the sequence from past to present\n",
    "X_train = X_train.reshape(-1, HISTORY_LEN + 1, NUM_FEATURES)  # reshape for LSTM sequence input (num_samples, 11, 12)\n",
    "\n",
    "X_test_real = np.array(X_test_real)\n",
    "X_test_real = np.flip(X_test_real, axis=1)\n",
    "X_test_real = X_test_real.reshape(-1, HISTORY_LEN + 1, NUM_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Embedding\n",
    "\n",
    "dropout_rate = 0.5\n",
    "max_input_len,  data_point_dim = X_train.shape[1], X_train.shape[2]\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(32, return_sequences=False, dropout=dropout_rate, input_shape=(max_input_len, data_point_dim, )))\n",
    "lstm_model.add(Dense(6, activation='softmax'))  # applying softmax and cross entorpy loss\n",
    "lstm_model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1409265/1409265 [==============================] - 476s 338us/step - loss: 0.4948\n",
      "Epoch 2/5\n",
      "1409265/1409265 [==============================] - 475s 337us/step - loss: 0.3887\n",
      "Epoch 3/5\n",
      "1409265/1409265 [==============================] - 497s 353us/step - loss: 0.3646\n",
      "Epoch 4/5\n",
      "1409265/1409265 [==============================] - 503s 357us/step - loss: 0.3496\n",
      "Epoch 5/5\n",
      "1409265/1409265 [==============================] - 509s 361us/step - loss: 0.3409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11eabec88>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "num_activities = 6\n",
    "y_train_one_hot = np.array([to_categorical(t, num_activities) for t in y_train])\n",
    "\n",
    "# tranform y to one hot encoding vector of length 6 (we have 6 activities)\n",
    "lstm_model.fit(X_train, y_train_one_hot, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the LSTM model results on the real test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.81      0.48      0.60     52652\n",
      "        sit       0.48      0.97      0.64     35225\n",
      "        std       0.13      0.00      0.00     36561\n",
      "        ups       0.39      0.81      0.52     21800\n",
      "        jog       0.00      0.00      0.00         0\n",
      "        dws       0.43      0.38      0.40     19547\n",
      "\n",
      "avg / total       0.49      0.51      0.44    165785\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/okleinfeld/venv/ds_workshop/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "lstm_model_predictions = lstm_model.predict(X_test_real)\n",
    "lstm_model_test_predictions = np.argmax(lstm_model_predictions, axis=1)\n",
    "hist_test_processor.evaluate_results(y_test_real, lstm_model_test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
