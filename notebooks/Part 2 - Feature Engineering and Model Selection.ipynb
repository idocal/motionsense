{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MotiononSense Dataset\n",
    "### Problem definition: predict user's activity based on smartphone sensors data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2:\n",
    "\n",
    "* Problem Definition and Possible Applications\n",
    "* Feature Extraction / Engineering\n",
    "* Classic ML Models - Training and Statistical Evaluation\n",
    "* Problems and the Need for \"Real Data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem Definition and Applications\n",
    "\n",
    "* Our problem is predicting user's activity from phone sensors data\n",
    "* This definition might be too wide, so we limit ourself to predicting 1 of 5 possible activities\n",
    "* Thus, we can define our problem as multiclass classification, where we can label each data point as <br> sitting, standing, walking, going downstaris or going upstairs \n",
    "* There are many application for this kind of classification in various fields such as <br> healthcare, intelligence etc. \n",
    "* We will further discuss some of these applications in later part of our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Feature Extraction / Engineering\n",
    "\n",
    "Our data is a time series - a sequence of measurements over time\n",
    "\n",
    "* Thus, extracting value for a single data point depends on it's context\n",
    "* But, classic ML algorithms/classifiers predicts output for a single input data point - independent to adjacent input data point\n",
    "* So, in order to use our data to train classic ML model we will have to encode our features to represent context data \n",
    "* We will present two different features encoding methods - Sliding-Window and Raw-History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window Features\n",
    "\n",
    "\n",
    "* In this method, we will encode each data sample as a concatenation of analytical functions calculated over a predefined size of previous samples\n",
    "* For example, here we will use a context size of 10 (calculate over 10 pervious data points)\n",
    "* Notice that we cannot mix between different expirements who represents different activity label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "PROJECT_MAIN_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindow:\n",
    "    \n",
    "    def __init__(self, orig_df, window_size, num_experiments, num_participants, exclude, fnlist):\n",
    "        exps = [i for i in range(1,num_experiments + 1) if i != exclude]\n",
    "        parts = [i for i in range(1,num_participants + 1)]\n",
    "        smp_df = self.create_sliding_df(orig_df, window_size, fnlist, exps, parts)\n",
    "        self.window_size = window_size\n",
    "        self.df = smp_df\n",
    "\n",
    "    def create_sld_df_single_exp(self, orig_df, window_size, analytic_functions_list):\n",
    "        dfs_to_concate = []\n",
    "        base_df = orig_df.drop('action', axis=1)\n",
    "        for func in analytic_functions_list:\n",
    "            method_to_call = getattr(base_df.rolling(window=window_size), func)\n",
    "            analytic_df = method_to_call()\n",
    "            analytic_df = analytic_df[window_size:]\n",
    "            analytic_df.columns = [col + \"_sld_\" + func for col in analytic_df.columns]\n",
    "            dfs_to_concate.append(analytic_df)\n",
    "\n",
    "        action_df = orig_df[['action']][window_size:] # [[]] syntax to return DataFrame and not Series\n",
    "        dfs_to_concate.append(action_df)\n",
    "        return pd.concat(dfs_to_concate,axis=1)\n",
    "\n",
    "    def create_sliding_df(self, orig_df, window_size, analytic_functions_list, expirements, participants):\n",
    "        dfs_to_concate = []\n",
    "        cols_to_drop = ['partc', 'action_file_index']\n",
    "        for e in expirements:\n",
    "            for p in participants:\n",
    "                exp_df = orig_df[(orig_df['partc'] == p) & (orig_df['action_file_index'] == e)]\n",
    "                exp_df = exp_df.drop(cols_to_drop, axis=1)\n",
    "                exp_roll_df = self.create_sld_df_single_exp(exp_df, window_size, analytic_functions_list)\n",
    "\n",
    "                dfs_to_concate.append(exp_roll_df)\n",
    "        return pd.concat(dfs_to_concate, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(PROJECT_MAIN_DIR,'full_data.gz'), compression='gzip') # we will load our data saved as a compressed csv file\n",
    "df = df.drop(['Unnamed: 0'], axis=1).set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables for the sliding window data frame creation\n",
    "num_experiments = 16\n",
    "num_participants = 24\n",
    "exclude = 10\n",
    "analytic_functions_list = ['mean', 'sum', 'median', 'min', 'max', 'std']\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "# create the sliding window data frame\n",
    "win_df = SlidingWindow(df, WINDOW_SIZE, num_experiments, num_participants, exclude, analytic_functions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing our data and performing sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attitude.roll_sld_mean</th>\n",
       "      <th>attitude.pitch_sld_mean</th>\n",
       "      <th>attitude.yaw_sld_mean</th>\n",
       "      <th>gravity.x_sld_mean</th>\n",
       "      <th>gravity.y_sld_mean</th>\n",
       "      <th>gravity.z_sld_mean</th>\n",
       "      <th>rotationRate.x_sld_mean</th>\n",
       "      <th>rotationRate.y_sld_mean</th>\n",
       "      <th>rotationRate.z_sld_mean</th>\n",
       "      <th>userAcceleration.x_sld_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>gravity.x_sld_std</th>\n",
       "      <th>gravity.y_sld_std</th>\n",
       "      <th>gravity.z_sld_std</th>\n",
       "      <th>rotationRate.x_sld_std</th>\n",
       "      <th>rotationRate.y_sld_std</th>\n",
       "      <th>rotationRate.z_sld_std</th>\n",
       "      <th>userAcceleration.x_sld_std</th>\n",
       "      <th>userAcceleration.y_sld_std</th>\n",
       "      <th>userAcceleration.z_sld_std</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.476032</td>\n",
       "      <td>-0.699698</td>\n",
       "      <td>0.659227</td>\n",
       "      <td>0.761074</td>\n",
       "      <td>0.643965</td>\n",
       "      <td>-0.072516</td>\n",
       "      <td>0.327435</td>\n",
       "      <td>-0.237590</td>\n",
       "      <td>0.125294</td>\n",
       "      <td>0.089179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.029224</td>\n",
       "      <td>0.346436</td>\n",
       "      <td>0.590791</td>\n",
       "      <td>0.249107</td>\n",
       "      <td>0.083854</td>\n",
       "      <td>0.128267</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>dws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.464487</td>\n",
       "      <td>-0.697192</td>\n",
       "      <td>0.650675</td>\n",
       "      <td>0.761804</td>\n",
       "      <td>0.642056</td>\n",
       "      <td>-0.081426</td>\n",
       "      <td>0.344311</td>\n",
       "      <td>-0.346253</td>\n",
       "      <td>0.059212</td>\n",
       "      <td>0.058162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.029167</td>\n",
       "      <td>0.377046</td>\n",
       "      <td>0.554298</td>\n",
       "      <td>0.172086</td>\n",
       "      <td>0.087612</td>\n",
       "      <td>0.140744</td>\n",
       "      <td>0.099833</td>\n",
       "      <td>dws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.448353</td>\n",
       "      <td>-0.695176</td>\n",
       "      <td>0.639860</td>\n",
       "      <td>0.761559</td>\n",
       "      <td>0.640510</td>\n",
       "      <td>-0.093848</td>\n",
       "      <td>0.481461</td>\n",
       "      <td>-0.525592</td>\n",
       "      <td>0.033799</td>\n",
       "      <td>0.054865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.032387</td>\n",
       "      <td>0.428049</td>\n",
       "      <td>0.712118</td>\n",
       "      <td>0.141470</td>\n",
       "      <td>0.090179</td>\n",
       "      <td>0.146393</td>\n",
       "      <td>0.097535</td>\n",
       "      <td>dws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.426500</td>\n",
       "      <td>-0.692378</td>\n",
       "      <td>0.625654</td>\n",
       "      <td>0.760575</td>\n",
       "      <td>0.638354</td>\n",
       "      <td>-0.110722</td>\n",
       "      <td>0.602284</td>\n",
       "      <td>-0.699763</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>0.055195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.043814</td>\n",
       "      <td>0.439572</td>\n",
       "      <td>1.006450</td>\n",
       "      <td>0.168158</td>\n",
       "      <td>0.089927</td>\n",
       "      <td>0.148507</td>\n",
       "      <td>0.104310</td>\n",
       "      <td>dws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.399383</td>\n",
       "      <td>-0.688014</td>\n",
       "      <td>0.609652</td>\n",
       "      <td>0.758815</td>\n",
       "      <td>0.634966</td>\n",
       "      <td>-0.131806</td>\n",
       "      <td>0.705380</td>\n",
       "      <td>-0.951931</td>\n",
       "      <td>0.111215</td>\n",
       "      <td>0.041147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.008968</td>\n",
       "      <td>0.062607</td>\n",
       "      <td>0.433246</td>\n",
       "      <td>1.329760</td>\n",
       "      <td>0.224856</td>\n",
       "      <td>0.074548</td>\n",
       "      <td>0.091135</td>\n",
       "      <td>0.131904</td>\n",
       "      <td>dws</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attitude.roll_sld_mean  attitude.pitch_sld_mean  attitude.yaw_sld_mean  \\\n",
       "0                1.476032                -0.699698               0.659227   \n",
       "1                1.464487                -0.697192               0.650675   \n",
       "2                1.448353                -0.695176               0.639860   \n",
       "3                1.426500                -0.692378               0.625654   \n",
       "4                1.399383                -0.688014               0.609652   \n",
       "\n",
       "   gravity.x_sld_mean  gravity.y_sld_mean  gravity.z_sld_mean  \\\n",
       "0            0.761074            0.643965           -0.072516   \n",
       "1            0.761804            0.642056           -0.081426   \n",
       "2            0.761559            0.640510           -0.093848   \n",
       "3            0.760575            0.638354           -0.110722   \n",
       "4            0.758815            0.634966           -0.131806   \n",
       "\n",
       "   rotationRate.x_sld_mean  rotationRate.y_sld_mean  rotationRate.z_sld_mean  \\\n",
       "0                 0.327435                -0.237590                 0.125294   \n",
       "1                 0.344311                -0.346253                 0.059212   \n",
       "2                 0.481461                -0.525592                 0.033799   \n",
       "3                 0.602284                -0.699763                 0.062317   \n",
       "4                 0.705380                -0.951931                 0.111215   \n",
       "\n",
       "   userAcceleration.x_sld_mean   ...    gravity.x_sld_std  gravity.y_sld_std  \\\n",
       "0                     0.089179   ...             0.003243           0.006475   \n",
       "1                     0.058162   ...             0.001706           0.004752   \n",
       "2                     0.054865   ...             0.002168           0.004552   \n",
       "3                     0.055195   ...             0.004032           0.005687   \n",
       "4                     0.041147   ...             0.007015           0.008968   \n",
       "\n",
       "   gravity.z_sld_std  rotationRate.x_sld_std  rotationRate.y_sld_std  \\\n",
       "0           0.029224                0.346436                0.590791   \n",
       "1           0.029167                0.377046                0.554298   \n",
       "2           0.032387                0.428049                0.712118   \n",
       "3           0.043814                0.439572                1.006450   \n",
       "4           0.062607                0.433246                1.329760   \n",
       "\n",
       "   rotationRate.z_sld_std  userAcceleration.x_sld_std  \\\n",
       "0                0.249107                    0.083854   \n",
       "1                0.172086                    0.087612   \n",
       "2                0.141470                    0.090179   \n",
       "3                0.168158                    0.089927   \n",
       "4                0.224856                    0.074548   \n",
       "\n",
       "   userAcceleration.y_sld_std  userAcceleration.z_sld_std  action  \n",
       "0                    0.128267                    0.114783     dws  \n",
       "1                    0.140744                    0.099833     dws  \n",
       "2                    0.146393                    0.097535     dws  \n",
       "3                    0.148507                    0.104310     dws  \n",
       "4                    0.091135                    0.131904     dws  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_df.df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check:\n",
    "\n",
    "* There are 15 experiments and 24 participants for each expirement\n",
    "* For sliding window of 10 samples we are loosing 10 data samples of each experiment\n",
    "* This sums up to 15 \\* 24 \\* 10 = 3600\n",
    "* Indeed in the new data set there are exactly 3600 rows fewer than the origial data set\n",
    "* Furthermore, the new data set has exactly 12 \\* {num_analytical_function} + label column = 12 \\* 6 + 1 = 73 columns <br> (12 is the number of features in the original data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409265, 73)\n",
      "(1412865, 15)\n"
     ]
    }
   ],
   "source": [
    "print(win_df.df.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw History Features\n",
    "\n",
    "* In this method, we will simply encode each data sample as a concatenation of the raw features of it's previous x data points\n",
    "* For example, here we will use a context size of 10. i.e it is aligned with our previous sliding window method, <br> but instead of calculating aggregation of analytical function over the context features, here we simply encode them as a long vector\n",
    "* Again, we cannot mix between different expirements who represents different activity label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawHistory:\n",
    "    \n",
    "    def __init__(self, origin_df, history_length, num_experiments, num_participants, exclude):\n",
    "        exps = [i for i in range(1,num_experiments + 1) if i != exclude]\n",
    "        parts = [i for i in range(1,num_participants + 1)]\n",
    "        smp_df = self.create_history_encoded_df(origin_df, history_length, expirements=exps, participants=parts)\n",
    "        self.history_length = history_length\n",
    "        self.df = smp_df\n",
    "\n",
    "    def create_history_encoded_single_exp(self, orig_df, history_length):\n",
    "        hist_df = orig_df.copy(deep=True) # later operations are \"in place\" so we need to avoid changing original dataframe\n",
    "        columns_to_shift = hist_df.columns[:-1] # omit the action column, we don't want to duplicate it\n",
    "        for i in range(1,history_length + 1):\n",
    "            shift_df = orig_df.shift(i)\n",
    "            for col_name in columns_to_shift:\n",
    "                new_col_name = \"prev_{0}_\".format(i) + col_name\n",
    "                hist_df[new_col_name] = shift_df[col_name] # add shifted column, aka history, as a column to orignal dataframe\n",
    "\n",
    "        hist_df = hist_df[history_length:] # we don't return the first \"history_length\" sample - they have missing history data\n",
    "        return hist_df\n",
    "\n",
    "    def create_history_encoded_df(self, orig_df, history_length, expirements, participants):\n",
    "        dfs_to_concate = []\n",
    "        cols_to_drop = ['partc', 'action_file_index']\n",
    "        for e in expirements:\n",
    "            for p in participants:\n",
    "                exp_df = orig_df[(orig_df['partc'] == p) & (orig_df['action_file_index'] == e)]\n",
    "                exp_df = exp_df.drop(cols_to_drop, axis=1)\n",
    "                exp_histoy_df = self.create_history_encoded_single_exp(exp_df, history_length)\n",
    "                dfs_to_concate.append(exp_histoy_df)\n",
    "        return pd.concat(dfs_to_concate, axis=0, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables for the raw history data frame creation\n",
    "num_experiments = 16\n",
    "num_participants = 24\n",
    "exclude = 10\n",
    "HISTORY_LEN = 10\n",
    "\n",
    "# create the raw history data frame\n",
    "hist_df = RawHistory(df, HISTORY_LEN, num_experiments, num_participants, exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:**\n",
    "\n",
    "* There are 15 expirements and 24 participants for each expirement\n",
    "* For history encoded data with history length of 10 samples we are loosing 10 data samples of each expirement this sums up to 15 \\* 24 \\* 10 = 3600 \n",
    "* This sums up to 15 \\* 24 \\* 10 = 3600 \n",
    "* Indeed in the new data set there are exactly 3600 rows fewer than the origial data set <\\li>\n",
    "* Furthermore, the new data set has exactly 12 \\* {history_length + 1} + label columns = 12 * (10+1) + 1 = 133 columns <br> (addition of one for the original data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409265, 133)\n",
      "(1412865, 15)\n"
     ]
    }
   ],
   "source": [
    "print(hist_df.df.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Classic ML Models - Training and Statistical Evaluation\n",
    "\n",
    "* Now we have two different encodings of our time series data as independent data points.\n",
    "* We can feed them into an ML model and evaluate the performance of our predictions \n",
    "* First we will define a class to consolidate the functionality of splitting the data into training, development and test sets <br> and performing the evaluation using percision and recall for each activity label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class DataProcessingEval():\n",
    "    \n",
    "    def __init__(self, origin_df, labels_dict):\n",
    "        self.labels_dict = labels_dict\n",
    "        self.classes_names = self.create_classes(labels_dict)\n",
    "        self.df = origin_df\n",
    "    \n",
    "    def create_samples(self, division_ratio=[0.7, 0.1, 0.2]):\n",
    "        # Define X, y\n",
    "        df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        X, y = df.drop([\"action\"], axis=1), df[\"action\"]\n",
    "        y = y.replace(self.labels_dict)\n",
    "\n",
    "        # Divide to training, validation and test set\n",
    "        train_ratio, dev_ratio = division_ratio[0], division_ratio[1]\n",
    "        num_training = int(df.shape[0] * train_ratio)\n",
    "        num_validation = int(df.shape[0] * dev_ratio)\n",
    "\n",
    "        X_train, y_train = X[:num_training], y[:num_training]\n",
    "        X_vald, y_vald = X[num_training:num_training + num_validation], y[num_training:num_training + num_validation]\n",
    "        X_test, y_test = X[num_training + num_validation:], y[num_training + num_validation:]\n",
    "\n",
    "        return X_train, y_train, X_vald, y_vald, X_test, y_test\n",
    "\n",
    "    def create_classes(self, labels_dict):\n",
    "        classes_indexs = labels_dict.items()\n",
    "        classes_indexs = sorted(classes_indexs, key=lambda x: x[1])\n",
    "        classes_names = [label for label, index in classes_indexs]\n",
    "        return classes_names\n",
    "\n",
    "    def evaluate_results(self, y_true, y_pred):\n",
    "            print(\"---- Printing classification report ----\")\n",
    "            print(classification_report(y_true, y_pred, target_names=self.classes_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'wlk': 0, 'sit': 1, \"std\": 2, \"ups\": 3, \"jog\": 4, \"dws\": 5}\n",
    "\n",
    "win_processor = DataProcessingEval(win_df.df, labels_dict=labels)\n",
    "X_train_win, y_train_win, X_vald_win, y_vald_win, X_test_win, y_test_win = win_processor.create_samples()\n",
    "\n",
    "hist_processor = DataProcessingEval(hist_df.df, labels_dict=labels)\n",
    "X_train_hist, y_train_hist, X_vald_hist, y_vald_hist, X_test_hist, y_test_hist = hist_processor.create_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A few words about our evaluation metrics**\n",
    "\n",
    "* Our evaluation metrics will be precision, recall and their harmonic average the F1 score\n",
    "* These metrics are much more relevant to our problem compared to the model total accuracy for few reasons. \n",
    "* First, our problem is imbalanced. We've already seen that the labels walk sit and stand are x2 time more frequent than going up/down stairs \n",
    "* Second, We also consider our assumption that some activities will be much harder to predict compared to others. <br> i.e separating \"sit\" from \"walk\" should be much easier than separating between \"upstairs\" and \"downstairs\"\n",
    "* That is why we'll be interested in the model performance for each activity by its own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Model**\n",
    "\n",
    "* We will start with a simple linear model and evaluate its performnace using our two different encodings\n",
    "* We will use logistic regression with L2 loss function (MSE), with the default C=1.0 regularization value <br> (which defines our tradeoff between regularization term and actual loss in the loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=300, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_win = LogisticRegression(multi_class='multinomial', solver='lbfgs', verbose=1, max_iter=300)\n",
    "lr_win.fit(X_train_win, y_train_win)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an error that our model didn't converge - i.e the training stopped after reaching the maximum number of iterations instead of stopping due to our halting criteria threshold <br>\n",
    "Let's evalute its performace on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.61      0.82      0.70     34388\n",
      "        sit       0.99      0.99      0.99     33911\n",
      "        std       0.97      0.98      0.97     30358\n",
      "        ups       0.59      0.46      0.52     15940\n",
      "        jog       0.85      0.83      0.84     13245\n",
      "        dws       0.52      0.21      0.30     13084\n",
      "\n",
      "avg / total       0.79      0.80      0.78    140926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_win_prediction = lr_win.predict(X_vald_win)\n",
    "win_processor.evaluate_results(y_vald_win, lr_win_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs quite well on sit and stand labels but not so well on the other activities <br>\n",
    "We can try and train with stronger regularization and evaluate the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.61      0.82      0.70     34388\n",
      "        sit       0.99      0.99      0.99     33911\n",
      "        std       0.97      0.98      0.98     30358\n",
      "        ups       0.59      0.45      0.51     15940\n",
      "        jog       0.85      0.83      0.84     13245\n",
      "        dws       0.52      0.22      0.31     13084\n",
      "\n",
      "avg / total       0.79      0.80      0.78    140926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_win_r = LogisticRegression(multi_class='multinomial', solver='lbfgs', verbose=1, max_iter=300, C=0.1)\n",
    "lr_win_r.fit(X_train_win, y_train_win)\n",
    "lr_win_r_prediction = lr_win_r.predict(X_vald_win)\n",
    "win_processor.evaluate_results(y_vald_win, lr_win_r_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't change much the results so we can keep our previuos regularization rate\n",
    "\n",
    "Now we will perform the same analysis over the raw history encoded sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.49      0.68      0.57     34516\n",
      "        sit       0.87      0.96      0.91     33832\n",
      "        std       0.55      0.76      0.64     30528\n",
      "        ups       0.45      0.17      0.25     15533\n",
      "        jog       0.53      0.10      0.17     13438\n",
      "        dws       0.45      0.14      0.21     13079\n",
      "\n",
      "avg / total       0.59      0.60      0.56    140926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_hist = LogisticRegression(multi_class='multinomial', solver='lbfgs', verbose=1, max_iter=300)\n",
    "lr_hist.fit(X_train_hist, y_train_hist)\n",
    "lr_hist_prediction = lr_hist.predict(X_vald_hist)\n",
    "hist_processor.evaluate_results(y_vald_hist, lr_hist_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:718: UserWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.49      0.68      0.57     34516\n",
      "        sit       0.86      0.96      0.91     33832\n",
      "        std       0.55      0.76      0.64     30528\n",
      "        ups       0.45      0.17      0.25     15533\n",
      "        jog       0.54      0.10      0.17     13438\n",
      "        dws       0.45      0.14      0.21     13079\n",
      "\n",
      "avg / total       0.59      0.60      0.56    140926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_r_hist = LogisticRegression(multi_class='multinomial', solver='lbfgs', verbose=1, max_iter=300, C=0.1)\n",
    "lr_r_hist.fit(X_train_hist, y_train_hist)\n",
    "lr_r_hist_prediction = lr_r_hist.predict(X_vald_hist)\n",
    "hist_processor.evaluate_results(y_vald_hist, lr_r_hist_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that the results of the same classifier with the raw history encoding are much worse compared to the sliding window encoding - even with the relatively \"easy\" to predict activities sit and stand \n",
    "* This leads to a conclusion that the data is not linearly separable with the raw history encoding, and might be even the same with the sliding window aggregation encoding \n",
    "*  Next, we will try a stronger, non linear model to try and incorporate more complexed relations between our features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "* We will evaluate the performance of a non linear random forest model over our two different encoding data sets \n",
    "* This model can be trained much faster due to options to parallelize the training of independent trees \n",
    "* We will run few different architectures of number of trees and evaluate them on our validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   37.1s remaining:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   59.7s finished\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating Random Forest model with 10 trees for sliding window encoding ----\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.97      0.99      0.98     34388\n",
      "        sit       1.00      1.00      1.00     33911\n",
      "        std       1.00      1.00      1.00     30358\n",
      "        ups       0.95      0.94      0.95     15940\n",
      "        jog       0.99      0.98      0.98     13245\n",
      "        dws       0.96      0.92      0.94     13084\n",
      "\n",
      "avg / total       0.98      0.98      0.98    140926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating Random Forest model with 20 trees for sliding window encoding ----\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.98      0.99      0.98     34388\n",
      "        sit       1.00      1.00      1.00     33911\n",
      "        std       1.00      1.00      1.00     30358\n",
      "        ups       0.97      0.96      0.96     15940\n",
      "        jog       0.99      0.98      0.99     13245\n",
      "        dws       0.97      0.94      0.96     13084\n",
      "\n",
      "avg / total       0.99      0.99      0.99    140926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=8)]: Done  30 out of  30 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating Random Forest model with 30 trees for sliding window encoding ----\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.98      0.99      0.99     34388\n",
      "        sit       1.00      1.00      1.00     33911\n",
      "        std       1.00      1.00      1.00     30358\n",
      "        ups       0.97      0.96      0.97     15940\n",
      "        jog       0.99      0.99      0.99     13245\n",
      "        dws       0.97      0.95      0.96     13084\n",
      "\n",
      "avg / total       0.99      0.99      0.99    140926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=8)]: Done  40 out of  40 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating Random Forest model with 40 trees for sliding window encoding ----\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.98      0.99      0.99     34388\n",
      "        sit       1.00      1.00      1.00     33911\n",
      "        std       1.00      1.00      1.00     30358\n",
      "        ups       0.97      0.96      0.97     15940\n",
      "        jog       0.99      0.99      0.99     13245\n",
      "        dws       0.97      0.95      0.96     13084\n",
      "\n",
      "avg / total       0.99      0.99      0.99    140926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.2min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating Random Forest model with 50 trees for sliding window encoding ----\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.98      0.99      0.99     34388\n",
      "        sit       1.00      1.00      1.00     33911\n",
      "        std       1.00      1.00      1.00     30358\n",
      "        ups       0.97      0.96      0.97     15940\n",
      "        jog       0.99      0.99      0.99     13245\n",
      "        dws       0.97      0.96      0.97     13084\n",
      "\n",
      "avg / total       0.99      0.99      0.99    140926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for i in range(10, 60, 10):\n",
    "    rf_win = RandomForestClassifier(n_estimators=i, n_jobs=-1, verbose=1)\n",
    "    rf_win.fit(X_train_win, y_train_win)\n",
    "    rf_win_prediction = rf_win.predict(X_vald_win)\n",
    "    print(\"----- Evaluating Random Forest model with {0} trees for {1} encoding ----\".format(i, \"sliding window\"))\n",
    "    win_processor.evaluate_results(y_vald_win, rf_win_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:  1.2min remaining:   46.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating Random Forest model with 10 trees for raw history encoding ----\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.93      0.98      0.96     34516\n",
      "        sit       1.00      1.00      1.00     33832\n",
      "        std       1.00      1.00      1.00     30528\n",
      "        ups       0.92      0.89      0.90     15533\n",
      "        jog       0.98      0.97      0.97     13438\n",
      "        dws       0.92      0.85      0.88     13079\n",
      "\n",
      "avg / total       0.96      0.97      0.96    140926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  3.2min finished\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating Random Forest model with 20 trees for raw history encoding ----\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.95      0.99      0.97     34516\n",
      "        sit       1.00      1.00      1.00     33832\n",
      "        std       1.00      1.00      1.00     30528\n",
      "        ups       0.94      0.91      0.93     15533\n",
      "        jog       0.98      0.97      0.98     13438\n",
      "        dws       0.94      0.90      0.92     13079\n",
      "\n",
      "avg / total       0.97      0.97      0.97    140926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=8)]: Done  30 out of  30 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating Random Forest model with 30 trees for raw history encoding ----\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.96      0.99      0.97     34516\n",
      "        sit       1.00      1.00      1.00     33832\n",
      "        std       1.00      1.00      1.00     30528\n",
      "        ups       0.95      0.92      0.93     15533\n",
      "        jog       0.99      0.97      0.98     13438\n",
      "        dws       0.94      0.91      0.93     13079\n",
      "\n",
      "avg / total       0.98      0.98      0.98    140926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.2min finished\n",
      "[Parallel(n_jobs=8)]: Done  40 out of  40 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating Random Forest model with 40 trees for raw history encoding ----\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.96      0.99      0.97     34516\n",
      "        sit       1.00      1.00      1.00     33832\n",
      "        std       1.00      1.00      1.00     30528\n",
      "        ups       0.95      0.92      0.93     15533\n",
      "        jog       0.99      0.97      0.98     13438\n",
      "        dws       0.94      0.91      0.93     13079\n",
      "\n",
      "avg / total       0.98      0.98      0.98    140926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.0min finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluating Random Forest model with 50 trees for raw history encoding ----\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.96      0.99      0.97     34516\n",
      "        sit       1.00      1.00      1.00     33832\n",
      "        std       1.00      1.00      1.00     30528\n",
      "        ups       0.95      0.93      0.94     15533\n",
      "        jog       0.99      0.98      0.98     13438\n",
      "        dws       0.94      0.92      0.93     13079\n",
      "\n",
      "avg / total       0.98      0.98      0.98    140926\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  50 out of  50 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 60, 10):\n",
    "    rf_hist = RandomForestClassifier(n_estimators=i, n_jobs=-1, verbose=1)\n",
    "    rf_hist.fit(X_train_hist, y_train_hist)\n",
    "    rf_hist_prediction = rf_hist.predict(X_vald_hist)\n",
    "    print(\"----- Evaluating Random Forest model with {0} trees for {1} encoding ----\".format(i, \"raw history\"))\n",
    "    hist_processor.evaluate_results(y_vald_hist, rf_hist_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see the differences due to the number of estimators is pretty much negligible \n",
    "* Using our sliding window encoding performs slightly better, especially for the upstaris and downstairs labels \n",
    "* We will choose the more simple model with only 10 tree estimators and the sliding window encoding\n",
    "* Next, we will anaylize the result of our best model so far over the test set portion we saved to ourselves (random forest with 10 trees using the sliding window encoding) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate best model on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   46.1s remaining:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.96      0.99      0.98     68697\n",
      "        sit       1.00      1.00      1.00     67600\n",
      "        std       1.00      1.00      1.00     61418\n",
      "        ups       0.96      0.94      0.95     31245\n",
      "        jog       0.99      0.98      0.98     26781\n",
      "        dws       0.97      0.93      0.94     26113\n",
      "\n",
      "avg / total       0.98      0.98      0.98    281854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10, n_jobs=-1, verbose=1)\n",
    "rf.fit(X_train_win, y_train_win)\n",
    "rf_win_test_predictions = rf.predict(X_test_win)\n",
    "win_processor.evaluate_results(y_test_win, rf_win_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problems and the Need for \"Real Data\"\n",
    "\n",
    "* As we can see, even on our left aside test data the performance of the model is too good to be true.\n",
    "* This is a reason to suspect that although we tested our model on data was not used to train it, **we are over-fitting to the current data set as a whole**\n",
    "* We suspect that **the generation process of the data was too \"synthetic\"**, not represeting \"real world\" data obtained from phone sensors\n",
    "* We used this experiment framework to **extract real data obtained from our activities** during the day and labeled them accordingly \n",
    "* In the next notebook we will present our model performance on our \"real world\" data and try to train more complex models to improve our performance over the real world data \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
