{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MotiononSense Dataset\n",
    "### Problem definition: predict user's activity based on smartphone sensors data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3:\n",
    "\n",
    "* Extracting Real World Data \n",
    "* Evaluation on Real World Data \n",
    "* Neural Models - Training and Evaluation on Real World Data\n",
    "* Applicative Predictions Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extracting Real World Data\n",
    "\n",
    "\n",
    "* We used the [Core Motion Framework for iOS devices](https://developer.apple.com/documentation/coremotion/cmdevicemotion) to extract sensors data from our phones\n",
    "* More details on the app we built can be found in our final document\n",
    "* We recorded sensors data while performing different activties and extracted labeled data samples \n",
    "* On the next section we will load our data and use it as a test set to evaluate the performace of our Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class NewDataLoader():\n",
    "    \n",
    "    def __init__(self, folder_path):\n",
    "        self.data_path = folder_path\n",
    "    \n",
    "    def load_all_expirements(self):\n",
    "        df = None\n",
    "        exp_index = 1\n",
    "        for filename in os.listdir(self.data_path):\n",
    "            file_path = os.path.join(self.data_path, filename)\n",
    "            extension = os.path.splitext(file_path)[1]\n",
    "            if extension == '.csv':\n",
    "                current_df = self.load_single_test_expirement(file_path, exp_index)\n",
    "                exp_index += 1\n",
    "                if df is None:\n",
    "                    df = current_df\n",
    "                else:\n",
    "                    df = df.append(current_df)\n",
    "        return df\n",
    "\n",
    "    def load_single_test_expirement(self, path_to_file, exp_index, partc_id=1):\n",
    "        cols_to_drop = [\"timestamp\", \"timeIntervalSince1970\", 'magneticField.x', \n",
    "                        'magneticField.y', 'magneticField.z', 'magneticField.accuracy']\n",
    "        file_name = path_to_file.split(os.sep)[-1]\n",
    "        name, file_type = file_name.split('.')\n",
    "        action = name[:3]\n",
    "        exp_df = pd.read_csv(path_to_file)\n",
    "        exp_df = exp_df.drop(cols_to_drop, axis=1)\n",
    "        exp_df[\"partc\"] = partc_id\n",
    "        exp_df[\"action\"] = action\n",
    "        exp_df[\"action_file_index\"] = exp_index\n",
    "        return exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_MAIN_DIR = os.getcwd()\n",
    "path = os.path.join(PROJECT_MAIN_DIR, 'real-data')\n",
    "data_loader = NewDataLoader(path)\n",
    "real_test_df = data_loader.load_all_expirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load also our original data set and use it as a training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PROJECT_MAIN_DIR,'full_data.gz'), compression='gzip') # we will load our data saved as a compressed csv file\n",
    "train_df = train_df.drop(['Unnamed: 0'], axis=1).set_index('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation on Real World Data\n",
    "\n",
    "Now, we will encode both samples with our Sliding Window encoding, train our Random Forest model over the entire old data and evaluate it's performance on the real world data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindow:\n",
    "    \n",
    "    def __init__(self, orig_df, window_size, num_experiments, num_participants, exclude, fnlist):\n",
    "        exps = [i for i in range(1,num_experiments + 1) if i != exclude]\n",
    "        parts = [i for i in range(1,num_participants + 1)]\n",
    "        smp_df = self.create_sliding_df(orig_df, window_size, fnlist, exps, parts)\n",
    "        self.window_size = window_size\n",
    "        self.df = smp_df\n",
    "\n",
    "    def create_sld_df_single_exp(self, orig_df, window_size, analytic_functions_list):\n",
    "        dfs_to_concate = []\n",
    "        base_df = orig_df.drop('action', axis=1)\n",
    "        for func in analytic_functions_list:\n",
    "            method_to_call = getattr(base_df.rolling(window=window_size), func)\n",
    "            analytic_df = method_to_call()\n",
    "            analytic_df = analytic_df[window_size:]\n",
    "            analytic_df.columns = [col + \"_sld_\" + func for col in analytic_df.columns]\n",
    "            dfs_to_concate.append(analytic_df)\n",
    "\n",
    "        action_df = orig_df[['action']][window_size:] # [[]] syntax to return DataFrame and not Series\n",
    "        dfs_to_concate.append(action_df)\n",
    "        return pd.concat(dfs_to_concate,axis=1)\n",
    "\n",
    "    def create_sliding_df(self, orig_df, window_size, analytic_functions_list, expirements, participants):\n",
    "        dfs_to_concate = []\n",
    "        cols_to_drop = ['partc', 'action_file_index']\n",
    "        for e in expirements:\n",
    "            for p in participants:\n",
    "                exp_df = orig_df[(orig_df['partc'] == p) & (orig_df['action_file_index'] == e)]\n",
    "                exp_df = exp_df.drop(cols_to_drop, axis=1)\n",
    "                exp_roll_df = self.create_sld_df_single_exp(exp_df, window_size, analytic_functions_list)\n",
    "\n",
    "                dfs_to_concate.append(exp_roll_df)\n",
    "        return pd.concat(dfs_to_concate, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining variables for the sliding window data frame creation\n",
    "num_experiments = 16\n",
    "num_participants = 24\n",
    "exclude = 10\n",
    "analytic_functions_list = ['mean', 'sum', 'median', 'min', 'max', 'std']\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "# create the sliding window data frame\n",
    "train_win_df = SlidingWindow(train_df, WINDOW_SIZE, num_experiments, num_participants, exclude, analytic_functions_list)\n",
    "train_win_df = train_win_df.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 18\n",
    "num_participants = 1\n",
    "exclude = 0\n",
    "analytic_functions_list = ['mean', 'sum', 'median', 'min', 'max', 'std']\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "real_test_df[\"partc\"] = 1\n",
    "test_win_df = SlidingWindow(real_test_df, WINDOW_SIZE, num_experiments, num_participants, exclude, analytic_functions_list)\n",
    "test_win_df = test_win_df.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class DataProcessingEval():\n",
    "    \n",
    "    def __init__(self, origin_df, labels_dict):\n",
    "        self.labels_dict = labels_dict\n",
    "        self.classes_names = self.create_classes(labels_dict)\n",
    "        self.df = origin_df\n",
    "    \n",
    "    def create_samples(self, division_ratio=[0.7, 0.1, 0.2]):\n",
    "        # Define X, y\n",
    "        df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "        X, y = df.drop([\"action\"], axis=1), df[\"action\"]\n",
    "        y = y.replace(self.labels_dict)\n",
    "\n",
    "        # Divide to training, validation and test set\n",
    "        train_ratio, dev_ratio = division_ratio[0], division_ratio[1]\n",
    "        num_training = int(df.shape[0] * train_ratio)\n",
    "        num_validation = int(df.shape[0] * dev_ratio)\n",
    "        \n",
    "        X_train, y_train = X[:num_training], y[:num_training]\n",
    "        X_vald, y_vald = X[num_training:num_training + num_validation], y[num_training:num_training + num_validation]\n",
    "        X_test, y_test = X[num_training + num_validation:], y[num_training + num_validation:]\n",
    "\n",
    "        return X_train, y_train, X_vald, y_vald, X_test, y_test\n",
    "\n",
    "    def create_classes(self, labels_dict):\n",
    "        classes_indexs = labels_dict.items()\n",
    "        classes_indexs = sorted(classes_indexs, key=lambda x: x[1])\n",
    "        classes_names = [label for label, index in classes_indexs]\n",
    "        return classes_names\n",
    "\n",
    "    def evaluate_results(self, y_true, y_pred):\n",
    "            print(\"---- Printing classification report ----\")\n",
    "            print(classification_report(y_true, y_pred, target_names=self.classes_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'wlk': 0, 'sit': 1, \"std\": 2, \"ups\": 3, \"jog\": 4, \"dws\": 5}\n",
    "\n",
    "win_train_processor = DataProcessingEval(train_win_df, labels_dict=labels)\n",
    "X_train, y_train, _, _, _, _  = win_train_processor.create_samples([1.0, 0, 0])\n",
    "\n",
    "win_test_processor = DataProcessingEval(test_win_df, labels_dict=labels)\n",
    "X_test_real, y_test_real, _, _, _, _ = win_test_processor.create_samples([1.0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training over the entire original data and evaluating on new test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   55.2s remaining:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.79      0.48      0.60     52652\n",
      "        sit       0.98      0.70      0.82     35225\n",
      "        std       0.97      0.97      0.97     36561\n",
      "        ups       0.44      0.75      0.55     21800\n",
      "        jog       0.00      0.00      0.00         0\n",
      "        dws       0.29      0.48      0.36     19547\n",
      "\n",
      "avg / total       0.76      0.67      0.69    165785\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   6 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=10, n_jobs=-1, verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_test_predictions = rf.predict(X_test_real)\n",
    "win_test_processor.evaluate_results(y_test_real, rf_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions so far:**\n",
    "\n",
    "* We excluded the \"jogging\" activity because we didn't perform this activity in the data we created from our app\n",
    "* As predicted, the results on real world data are much worse compared to results over our original test set\n",
    "* We are still predicting \"sit\" and \"stand\" activities quite well but our current model is having hard time identifying \"upstairs\" and \"down stairs\"\n",
    "* Next, we will try to use a stronger, neural models, hoping that it will help us increasing our performance over the real test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Neural Models - Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding for Neural Models**\n",
    "\n",
    "* The first model we will try is a simple feed forward network with one hidden layer\n",
    "* Feed forward nets, like classic ML models, cannot use sequence as input so we will have to use one of our previous encodings \n",
    "* We will choose our sliding window encoding first, since it out-performed our raw history encoding\n",
    "* We hope that our model can create a better representation of the data in it's hidden layer and thus increase the generalization ability of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1409265, 73)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_win_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "ff_model = Sequential()\n",
    "ff_model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))  # hidden layer size is 32\n",
    "ff_model.add(Dropout(dropout_rate))  # adding dropout layer\n",
    "ff_model.add(Dense(6, activation='softmax'))  # applying softmax and cross entorpy loss\n",
    "ff_model.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1409265/1409265 [==============================] - 83s 59us/step - loss: 0.5426\n",
      "Epoch 2/5\n",
      "1409265/1409265 [==============================] - 82s 58us/step - loss: 0.4871\n",
      "Epoch 3/5\n",
      "1409265/1409265 [==============================] - 82s 58us/step - loss: 0.4795\n",
      "Epoch 4/5\n",
      "1409265/1409265 [==============================] - 81s 58us/step - loss: 0.4761\n",
      "Epoch 5/5\n",
      "1409265/1409265 [==============================] - 83s 59us/step - loss: 0.4736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e117518>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "num_activities = 6\n",
    "y_train_one_hot = np.array([to_categorical(t, num_activities) for t in y_train])\n",
    "\n",
    "# tranform y to one hot encoding vector of length 6 (we have 6 activities)\n",
    "ff_model.fit(X_train, y_train_one_hot, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.79      0.56      0.66     52652\n",
      "        sit       0.96      0.97      0.96     35225\n",
      "        std       0.90      0.97      0.93     36561\n",
      "        ups       0.36      0.72      0.48     21800\n",
      "        jog       0.00      0.00      0.00         0\n",
      "        dws       0.42      0.20      0.27     19547\n",
      "\n",
      "avg / total       0.75      0.72      0.71    165785\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_test_real_one_hot = np.array([to_categorical(t, num_activities) for t in y_test_real])\n",
    "ff_predictions = ff_model.predict(X_test_real)\n",
    "ff_test_predictions = np.array([np.argmax(prediction) for prediction in ff_predictions])\n",
    "win_test_processor.evaluate_results(y_test_real, ff_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate results:**\n",
    "* Results for Feed Forward neural network look like the Random Forest ones\n",
    "* Try to add another hidden layer and see if significant improvement occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1409265/1409265 [==============================] - 94s 67us/step - loss: 0.4216 0s - l\n",
      "Epoch 2/5\n",
      "1409265/1409265 [==============================] - 98s 69us/step - loss: 0.3405\n",
      "Epoch 3/5\n",
      "1409265/1409265 [==============================] - 107s 76us/step - loss: 0.3259\n",
      "Epoch 4/5\n",
      "1409265/1409265 [==============================] - 93s 66us/step - loss: 0.3180\n",
      "Epoch 5/5\n",
      "1409265/1409265 [==============================] - 88s 63us/step - loss: 0.3128\n",
      "---- Printing classification report ----\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        wlk       0.84      0.52      0.64     52652\n",
      "        sit       0.93      0.98      0.95     35225\n",
      "        std       0.95      0.97      0.96     36561\n",
      "        ups       0.39      0.74      0.51     21800\n",
      "        jog       0.00      0.00      0.00         0\n",
      "        dws       0.41      0.35      0.38     19547\n",
      "\n",
      "avg / total       0.78      0.72      0.73    165785\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "ff2_model = Sequential()\n",
    "ff2_model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))  # first hidden layer size is 32\n",
    "ff2_model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))  # second hidden layer size is 32\n",
    "ff2_model.add(Dropout(dropout_rate))  # adding dropout layer\n",
    "ff2_model.add(Dense(6, activation='softmax'))  # applying softmax and cross entorpy loss\n",
    "ff2_model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "ff2_model.fit(X_train, y_train_one_hot, batch_size=32, epochs=5)\n",
    "\n",
    "ff2_predictions = ff2_model.predict(X_test_real)\n",
    "ff2_test_predictions = np.array([np.argmax(prediction) for prediction in ff2_predictions])\n",
    "win_test_processor.evaluate_results(y_test_real, ff2_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intermediate neural conclusions:**\n",
    "* Normal feed forward does not perform much better than random forest\n",
    "* Adding another layer did not improve at all the F1-score\n",
    "* This might be because our sliding window is not an ideal input for time series neural network\n",
    "* Possibly, other architectures like RNN would have worked better, but we do not focus these"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Applicative Predictions Smoothing\n",
    "\n",
    "* Here we present a simple concept which works well in practice\n",
    "* Instead of adding complexity to our model, we smooth the predictions\n",
    "* We assume that real world activities last at least **3 seconds**\n",
    "* Thus, we use a majority vote smoothing technique, with a factor of **30 predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload real data experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_MAIN_DIR = os.getcwd()\n",
    "path = os.path.join(PROJECT_MAIN_DIR, 'real-data')\n",
    "data_loader = NewDataLoader(path)\n",
    "real_test_df = data_loader.load_all_expirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 18\n",
    "num_participants = 1\n",
    "exclude = 0\n",
    "analytic_functions_list = ['mean', 'sum', 'median', 'min', 'max', 'std']\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "real_test_df[\"partc\"] = 1\n",
    "test_win_df = SlidingWindow(real_test_df, WINDOW_SIZE, num_experiments, num_participants, exclude, analytic_functions_list)\n",
    "test_win_df = test_win_df.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new preprocessig should not shuffle activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothDataEval:\n",
    "    \n",
    "    def __init__(self, origin_df, labels_dict, smooth_factor):\n",
    "        self.labels_dict = labels_dict\n",
    "        self.classes_names = self.create_classes(labels_dict)\n",
    "        self.df = origin_df\n",
    "        self.smooth_factor = smooth_factor\n",
    "        \n",
    "    def create_samples(self):\n",
    "        # Define X, y\n",
    "        X, y = self.df.drop([\"action\"], axis=1), self.df[\"action\"]\n",
    "        y = y.replace(self.labels_dict)\n",
    "        return X, y\n",
    "        \n",
    "    def create_classes(self, labels_dict):\n",
    "        classes_indexs = labels_dict.items()\n",
    "        classes_indexs = sorted(classes_indexs, key=lambda x: x[1])\n",
    "        classes_names = [label for label, index in classes_indexs]\n",
    "        return classes_names\n",
    "    \n",
    "    def smooth_predictions(predictions, smooth_factor):\n",
    "    \n",
    "        new_predictions = []\n",
    "        \n",
    "        def batch_predictions():\n",
    "            batches = []\n",
    "            gap = len(predictions) % smooth_factor\n",
    "            num_groups = len(predictions) // smooth_factor\n",
    "            random_groups = np.random.choice(num_groups, gap, replace=False)\n",
    "            \n",
    "            current_group = 0\n",
    "            i = 0\n",
    "            \n",
    "            while i < len(predictions):\n",
    "                batch_size = smooth_factor\n",
    "                if current_group in random_groups:\n",
    "                    batch_size += 1\n",
    "                \n",
    "                batches.append(predictions[i:i + batch_size])\n",
    "                i += batch_size\n",
    "                current_group += 1\n",
    "            \n",
    "            return batches\n",
    "\n",
    "        def majority_smooth(batch):\n",
    "            batch = batch.tolist()\n",
    "            most_common = max(set(batch), key=batch.count)\n",
    "            return [most_common] * len(batch)\n",
    "\n",
    "        batches = batch_predictions()\n",
    "        for batch in batches:\n",
    "            new_predictions.extend(majority_smooth(batch))\n",
    "\n",
    "        return new_predictions\n",
    "\n",
    "    def evaluate_results(self, y_true, y_pred):\n",
    "        print(\"---- Printing classification report ----\")\n",
    "        print(classification_report(y_true, y_pred, target_names=self.classes_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our smooth factor and smooth RF predictions, then re-evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOOTH_FACTOR = 30\n",
    "labels = {'wlk': 0, 'sit': 1, \"std\": 2, \"ups\": 3, \"jog\": 4, \"dws\": 5}\n",
    "smooth_data_processor = SmoothDataEval(test_win_df, labels, SMOOTH_FACTOR)\n",
    "X, y = smooth_data_processor.create_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = rf.predict(X)\n",
    "smooth_rf_predictions = SmoothDataEval.smooth_predictions(rf_predictions, SMOOTH_FACTOR)\n",
    "smooth_data_processor.evaluate_results(y ,smooth_rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "* The results now look better than the naïve Random Forest.\n",
    "* We used a very simple smoothing technique with a constant factor\n",
    "* It's reasonable to assume that more sophisticaed filters would result in even better result\n",
    "* The applicative solution works well in practice\n",
    "* We now provide the user with a prediction every 3 seconds instead of every 0.1 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
